# LLM Configuration v0.1
defaults:
  model: "moonshotai/kimi-k2:free"
  n_consistency: 3
  temperature: 0.0
  top_p: 1.0
  max_tokens: 800
  cache_enabled: true
  logs_enabled: true

# Budgets per operator
budgets:
  meet:
    tokens: 400
    latency_ms: 2000
  generalize:
    tokens: 600
    latency_ms: 3000
  refute:
    tokens: 300
    latency_ms: 1500
  specialize:
    tokens: 500
    latency_ms: 2500
  contrast:
    tokens: 400
    latency_ms: 2000
  normalize:
    tokens: 300
    latency_ms: 1500
  verify:
    tokens: 200
    latency_ms: 1000

# Retry configuration
retry:
  max_attempts: 5
  base_delay: 0.5
  max_delay: 4.0
  exponential_base: 2.0

# Security
security:
  log_redaction: true
  hmac_secret_env: "LLM_LOG_SECRET"
  cache_ttl_hours: 24
  max_prompt_length: 10000
