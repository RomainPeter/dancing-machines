name: bench-active

on:
  pull_request:
    branches: [ main ]
    paths:
      - "scripts/**"
      - "proofengine/metrics.py"
      - "proofengine/orchestrator/modes.py"
      - ".github/workflows/bench-active.yml"

jobs:
  bench:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      
      - run: pip install -r requirements.txt
      
      - name: Download baseline metrics
        uses: actions/download-artifact@v4
        with:
          name: metrics_baseline
          path: artifacts/bench_public/
      
      - name: Run active benchmark with fairness gate
        env:
          METRICS_FAIRNESS: "1"
        run: |
          python scripts/bench_2cat.py \
            --suite corpus/bench_public/suite.json \
            --mode active \
            --runs 3 \
            --out artifacts/bench_public/metrics_active.json \
            --verifier mock \
            --compare artifacts/bench_public/metrics_baseline.json \
            --fairness
      
      - name: Upload active metrics
        uses: actions/upload-artifact@v4
        with:
          name: metrics_active
          path: artifacts/bench_public/metrics_active.json
